{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_9260/2369202826.py:3: DtypeWarning: Columns (19,47,55,112,123,124,125,128,129,130,133,139,140,141) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('gs://rob_buck/loan.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.56</td>\n",
       "      <td>84.92</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>18.94</td>\n",
       "      <td>777.23</td>\n",
       "      <td>D</td>\n",
       "      <td>D2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>17.97</td>\n",
       "      <td>180.69</td>\n",
       "      <td>D</td>\n",
       "      <td>D1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>18.94</td>\n",
       "      <td>146.51</td>\n",
       "      <td>D</td>\n",
       "      <td>D2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>16.14</td>\n",
       "      <td>731.78</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0 NaN        NaN       2500         2500           2500.0   36 months   \n",
       "1 NaN        NaN      30000        30000          30000.0   60 months   \n",
       "2 NaN        NaN       5000         5000           5000.0   36 months   \n",
       "3 NaN        NaN       4000         4000           4000.0   36 months   \n",
       "4 NaN        NaN      30000        30000          30000.0   60 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade  ... hardship_payoff_balance_amount  \\\n",
       "0     13.56        84.92     C        C1  ...                            NaN   \n",
       "1     18.94       777.23     D        D2  ...                            NaN   \n",
       "2     17.97       180.69     D        D1  ...                            NaN   \n",
       "3     18.94       146.51     D        D2  ...                            NaN   \n",
       "4     16.14       731.78     C        C4  ...                            NaN   \n",
       "\n",
       "  hardship_last_payment_amount disbursement_method  debt_settlement_flag  \\\n",
       "0                          NaN                Cash                     N   \n",
       "1                          NaN                Cash                     N   \n",
       "2                          NaN                Cash                     N   \n",
       "3                          NaN                Cash                     N   \n",
       "4                          NaN                Cash                     N   \n",
       "\n",
       "  debt_settlement_flag_date settlement_status settlement_date  \\\n",
       "0                       NaN               NaN             NaN   \n",
       "1                       NaN               NaN             NaN   \n",
       "2                       NaN               NaN             NaN   \n",
       "3                       NaN               NaN             NaN   \n",
       "4                       NaN               NaN             NaN   \n",
       "\n",
       "  settlement_amount  settlement_percentage settlement_term  \n",
       "0               NaN                    NaN             NaN  \n",
       "1               NaN                    NaN             NaN  \n",
       "2               NaN                    NaN             NaN  \n",
       "3               NaN                    NaN             NaN  \n",
       "4               NaN                    NaN             NaN  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('gs://rob_buck/loan.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2260668, 145)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_default'] = df['loan_status'].map({\n",
    "    'Fully Paid': 0,\n",
    "    'Current': 0,\n",
    "    'In Grace Period': 0,\n",
    "    'Does not meet the credit policy. Status:Fully Paid': 0,\n",
    "    \n",
    "    'Charged Off': 1,\n",
    "    'Default': 1,\n",
    "    'Late (31-120 days)': 1,\n",
    "    'Late (16-30 days)': 1,\n",
    "    'Does not meet the credit policy. Status:Charged Off': 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_features = [\n",
    "    'grade', 'int_rate', 'home_ownership', 'revol_util', \n",
    "    'loan_amnt', 'annual_inc', 'dti',\n",
    "    'term', 'verification_status', 'inq_last_6mths', \n",
    "    'open_acc', 'pub_rec', 'total_acc', \n",
    "    'earliest_cr_line', 'acc_now_delinq',\n",
    "    'is_default'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[key_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2260668, 16)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grade                     0\n",
       "int_rate                  0\n",
       "home_ownership            0\n",
       "revol_util             1802\n",
       "loan_amnt                 0\n",
       "annual_inc                4\n",
       "dti                    1711\n",
       "term                      0\n",
       "verification_status       0\n",
       "inq_last_6mths           30\n",
       "open_acc                 29\n",
       "pub_rec                  29\n",
       "total_acc                29\n",
       "earliest_cr_line         29\n",
       "acc_now_delinq           29\n",
       "is_default                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['annual_inc'] = df['annual_inc'].fillna(df['annual_inc'].mean())\n",
    "df['dti'] = df['dti'].fillna(df['dti'].median())\n",
    "df['delinq_2yrs'] = df['delinq_2yrs'].fillna(df['delinq_2yrs'].median())\n",
    "df['revol_util'] = df['revol_util'].fillna(df['revol_util'].median())\n",
    "df['emp_length'] = df['emp_length'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_amnt         0\n",
       "int_rate          0\n",
       "grade             0\n",
       "annual_inc        0\n",
       "dti               0\n",
       "delinq_2yrs       0\n",
       "revol_util        0\n",
       "emp_length        0\n",
       "home_ownership    0\n",
       "purpose           0\n",
       "is_default        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>grade</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>purpose</th>\n",
       "      <th>is_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2500</td>\n",
       "      <td>13.56</td>\n",
       "      <td>2</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>18.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30000</td>\n",
       "      <td>18.94</td>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>26.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>17.97</td>\n",
       "      <td>3</td>\n",
       "      <td>59280.0</td>\n",
       "      <td>10.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000</td>\n",
       "      <td>18.94</td>\n",
       "      <td>3</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>16.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30000</td>\n",
       "      <td>16.14</td>\n",
       "      <td>2</td>\n",
       "      <td>57250.0</td>\n",
       "      <td>26.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  grade  annual_inc    dti  delinq_2yrs  revol_util  \\\n",
       "0       2500     13.56      2     55000.0  18.24          0.0        10.3   \n",
       "1      30000     18.94      3     90000.0  26.52          0.0        24.2   \n",
       "2       5000     17.97      3     59280.0  10.51          0.0        19.1   \n",
       "3       4000     18.94      3     92000.0  16.74          0.0        78.1   \n",
       "4      30000     16.14      2     57250.0  26.35          0.0         3.6   \n",
       "\n",
       "   emp_length  home_ownership  purpose  is_default  \n",
       "0           1               5        2           0  \n",
       "1           1               1        2           0  \n",
       "2           6               1        2           0  \n",
       "3           1               1        2           0  \n",
       "4           1               1        2           0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# OneHot encode categorical columns directly\n",
    "for col in ['grade', 'emp_length', 'home_ownership', 'purpose']:\n",
    "   encoder = LabelEncoder()\n",
    "   df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loan_amnt', 'int_rate', 'grade', 'annual_inc', 'dti', 'delinq_2yrs',\n",
       "       'revol_util', 'emp_length', 'home_ownership', 'purpose', 'is_default'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('is_default', axis=1), df['is_default'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1808534, 10)\n",
      "X_test_scaled shape: (452134, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_param_dist = {\n",
    "    'n_estimators': randint(200, 1000),\n",
    "    \n",
    "    'learning_rate': uniform(0.01, 0.2),  # 0.01 to 0.21\n",
    "    \n",
    "    'max_depth': randint(3, 10),\n",
    "    \n",
    "    'min_samples_split': randint(10, 100),\n",
    "    \n",
    "    'min_samples_leaf': randint(5, 50),\n",
    "    \n",
    "    'subsample': uniform(0.7, 0.3),  # 0.7 to 1.0\n",
    "    \n",
    "    'max_features': ['sqrt', 'log2', 0.3, 0.5, 0.7, None],\n",
    "    \n",
    "    'min_weight_fraction_leaf': uniform(0.0, 0.1),\n",
    "    \n",
    "    'ccp_alpha': uniform(0.0, 0.01),\n",
    "    \n",
    "    'validation_fraction': uniform(0.1, 0.1),  # 0.1 to 0.2\n",
    "    \n",
    "    'tol': uniform(1e-5, 1e-3),\n",
    "    \n",
    "    'n_iter_no_change': randint(5, 20)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingClassifier(\n",
    "    random_state=42,\n",
    "    warm_start=False,\n",
    "    verbose=1  # Show progress during training\n",
    ")\n",
    "\n",
    "# Set up RandomizedSearchCV with optimized settings for large datasets\n",
    "gb_random_search = RandomizedSearchCV(\n",
    "    estimator=gb_model,\n",
    "    param_distributions=gb_param_dist,\n",
    "    n_iter=50,  # Number of parameter combinations to try\n",
    "    cv=3,       # 3-fold cross-validation (faster for large datasets)\n",
    "    scoring='roc_auc',  # Optimize for ROC-AUC\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    verbose=2,  # Show detailed progress\n",
    "    random_state=42,\n",
    "    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7626          -0.0000           35.46m\n",
      "         2           0.7619          -0.0026           36.28m\n",
      "         3           0.7505           0.0147           36.04m\n",
      "         4           0.7504          -0.0004           35.67m\n",
      "         5           0.7513           0.0036           35.54m\n",
      "         6           0.7516           0.0011           35.33m\n",
      "         7           0.7493          -0.0093           35.46m\n",
      "         8           0.7500           0.0027           35.55m\n",
      "         9           0.7512           0.0050           36.24m\n",
      "        10           0.7501          -0.0045           36.35m\n",
      "[CV] END ccp_alpha=0.003745401188473625, learning_rate=0.20014286128198325, max_depth=5, max_features=0.7, min_samples_leaf=25, min_samples_split=92, min_weight_fraction_leaf=0.00999749158180029, n_estimators=658, n_iter_no_change=12, subsample=0.8001125833417065, tol=0.00015286681792194077, validation_fraction=0.1650888472948853; total time=  52.3s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7626          -0.0000           18.06m\n",
      "         2           0.7625          -0.0008           19.05m\n",
      "         3           0.7626           0.0011           19.77m\n",
      "         4           0.7629           0.0017           19.52m\n",
      "         5           0.7628          -0.0008           19.37m\n",
      "         6           0.7629           0.0006           19.13m\n",
      "         7           0.7624          -0.0034           19.01m\n",
      "         8           0.7620          -0.0022           18.99m\n",
      "         9           0.7630           0.0066           19.04m\n",
      "        10           0.7629          -0.0008           18.78m\n",
      "[CV] END ccp_alpha=0.006375574713552132, learning_rate=0.18744254851526532, max_depth=3, max_features=0.3, min_samples_leaf=41, min_samples_split=56, min_weight_fraction_leaf=0.07132447872229951, n_estimators=968, n_iter_no_change=9, subsample=0.8683831592708489, tol=0.000780967179954561, validation_fraction=0.1493795596364391; total time=  13.3s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7631          -0.0000           20.41m\n",
      "         2           0.7623          -0.0050           20.36m\n",
      "         3           0.7630           0.0046           19.72m\n",
      "         4           0.7631           0.0005           19.24m\n",
      "         5           0.7624          -0.0046           19.74m\n",
      "         6           0.7619          -0.0033           19.32m\n",
      "         7           0.7628           0.0059           19.41m\n",
      "         8           0.7627          -0.0005           19.73m\n",
      "         9           0.7623          -0.0026           20.12m\n",
      "        10           0.7632           0.0056           20.00m\n",
      "[CV] END ccp_alpha=0.006375574713552132, learning_rate=0.18744254851526532, max_depth=3, max_features=0.3, min_samples_leaf=41, min_samples_split=56, min_weight_fraction_leaf=0.07132447872229951, n_estimators=968, n_iter_no_change=9, subsample=0.8683831592708489, tol=0.000780967179954561, validation_fraction=0.1493795596364391; total time=  14.0s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7622          -0.0000           12.53m\n",
      "         2           0.7635           0.0038           13.82m\n",
      "         3           0.7626          -0.0025           13.78m\n",
      "         4           0.7623          -0.0010           13.63m\n",
      "         5           0.7628           0.0012           14.15m\n",
      "         6           0.7624          -0.0009           14.00m\n",
      "         7           0.7627           0.0009           14.04m\n",
      "         8           0.7639           0.0032           14.05m\n",
      "         9           0.7612          -0.0075           14.10m\n",
      "        10           0.7631           0.0055           13.94m\n",
      "[CV] END ccp_alpha=0.006334037565104235, learning_rate=0.18429211803754356, max_depth=6, max_features=0.5, min_samples_leaf=48, min_samples_split=93, min_weight_fraction_leaf=0.08925589984899779, n_estimators=530, n_iter_no_change=14, subsample=0.736626386410202, tol=0.0003662978380769749, validation_fraction=0.19068284415457543; total time=  25.5s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7617          -0.0000            6.01m\n",
      "         2           0.7627           0.0050            5.74m\n",
      "         3           0.7623          -0.0021            5.97m\n",
      "         4           0.7632           0.0047            6.00m\n",
      "         5           0.7633           0.0001            6.02m\n",
      "         6           0.7626          -0.0033            6.02m\n",
      "         7           0.7634           0.0040            6.00m\n",
      "         8           0.7627          -0.0035            6.03m\n",
      "         9           0.7633           0.0032            5.99m\n",
      "        10           0.7633          -0.0005            5.96m\n",
      "[CV] END ccp_alpha=0.005026790232288615, learning_rate=0.02029575024999787, max_depth=7, max_features=sqrt, min_samples_leaf=5, min_samples_split=28, min_weight_fraction_leaf=0.06807054515547668, n_estimators=252, n_iter_no_change=16, subsample=0.8343349493719274, tol=0.000562893089071328, validation_fraction=0.15926967238793938; total time=  26.8s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7619          -0.0000           28.91m\n",
      "         2           0.7626           0.0044           29.75m\n",
      "         3           0.7628           0.0014           28.94m\n",
      "         4           0.7623          -0.0032           28.88m\n",
      "         5           0.7630           0.0043           28.64m\n",
      "         6           0.7628          -0.0017           28.62m\n",
      "[CV] END ccp_alpha=0.007121792213475359, learning_rate=0.05744981749936002, max_depth=7, max_features=0.5, min_samples_leaf=12, min_samples_split=16, min_weight_fraction_leaf=0.07209399242521293, n_estimators=839, n_iter_no_change=5, subsample=0.8627620691664697, tol=0.00051881407683876, validation_fraction=0.16363326181858956; total time=  14.1s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7638          -0.0000           11.09m\n",
      "         2           0.7613          -0.0075           10.09m\n",
      "         3           0.7628           0.0046           10.13m\n",
      "         4           0.7641           0.0040           10.08m\n",
      "         5           0.7635          -0.0018           10.08m\n",
      "         6           0.7620          -0.0046            9.99m\n",
      "         7           0.7617          -0.0009            9.95m\n",
      "         8           0.7611          -0.0017            9.96m\n",
      "[CV] END ccp_alpha=0.009283185625877254, learning_rate=0.09563682966346286, max_depth=7, max_features=0.3, min_samples_leaf=37, min_samples_split=72, min_weight_fraction_leaf=0.030569701928718187, n_estimators=360, n_iter_no_change=7, subsample=0.7508478240058277, tol=0.0005668012624583502, validation_fraction=0.1936154774160781; total time=  15.2s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7620          -0.0000           15.66m\n",
      "         2           0.7625           0.0025           15.61m\n",
      "         3           0.7623          -0.0010           16.19m\n",
      "         4           0.7617          -0.0034           16.29m\n",
      "         5           0.7634           0.0100           15.97m\n",
      "         6           0.7624          -0.0061           15.78m\n",
      "         7           0.7623          -0.0004           15.53m\n",
      "         8           0.7625           0.0013           15.69m\n",
      "         9           0.7621          -0.0027           15.58m\n",
      "        10           0.7632           0.0067           15.70m\n",
      "[CV] END ccp_alpha=0.007089109969101186, learning_rate=0.12056399538158155, max_depth=4, max_features=log2, min_samples_leaf=39, min_samples_split=59, min_weight_fraction_leaf=0.08670723185801038, n_estimators=724, n_iter_no_change=16, subsample=0.8534027196582813, tol=0.0005115162946871996, validation_fraction=0.17982951789667753; total time=  23.5s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7621          -0.0000           20.07m\n",
      "         2           0.7623           0.0022           21.31m\n",
      "         3           0.7627           0.0042           21.30m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7626          -0.0000           11.74m\n",
      "         2           0.7552          -0.0017           11.57m\n",
      "         3           0.7552           0.0030           11.32m\n",
      "         4           0.7487           0.0009           11.38m\n",
      "         5           0.7489           0.0083           11.42m\n",
      "         6           0.7486          -0.0119           11.41m\n",
      "         7           0.7438           0.0285           11.38m\n",
      "         8           0.7434          -0.0179           11.47m\n",
      "         9           0.7433          -0.0017           11.29m\n",
      "        10           0.7433          -0.0003           11.23m\n",
      "        20           0.7395          -0.0109           11.09m\n",
      "        30           0.7398           0.0069           10.81m\n",
      "[CV] END ccp_alpha=0.0020794166286818884, learning_rate=0.1235400655639983, max_depth=7, max_features=log2, min_samples_leaf=30, min_samples_split=53, min_weight_fraction_leaf=0.09394989415641891, n_estimators=469, n_iter_no_change=19, subsample=0.976562270506935, tol=9.849250205191949e-05, validation_fraction=0.11959828624191453; total time=  49.2s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7630          -0.0000            7.33m\n",
      "         2           0.7633           0.0011            7.05m\n",
      "         3           0.7621          -0.0046            6.84m\n",
      "         4           0.7626           0.0020            6.80m\n",
      "         5           0.7624          -0.0010            6.69m\n",
      "         6           0.7612          -0.0045            6.72m\n",
      "         7           0.7629           0.0066            6.74m\n",
      "         8           0.7632           0.0013            6.71m\n",
      "         9           0.7628          -0.0016            6.66m\n",
      "        10           0.7632           0.0013            6.69m\n",
      "[CV] END ccp_alpha=0.009263008785133489, learning_rate=0.1402154051003889, max_depth=6, max_features=sqrt, min_samples_leaf=12, min_samples_split=21, min_weight_fraction_leaf=0.03308980248526492, n_estimators=247, n_iter_no_change=11, subsample=0.7932946965146986, tol=0.0003351833220267471, validation_fraction=0.1729606178338064; total time=  21.8s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7574           0.0055           45.29m\n",
      "         2           0.7567          -0.0023           47.80m\n",
      "         3           0.7530           0.0096           47.44m\n",
      "         4           0.7466          -0.0014           47.45m\n",
      "         5           0.7443           0.0074           47.44m\n",
      "         6           0.7444           0.0004           47.34m\n",
      "         7           0.7435          -0.0029           46.74m\n",
      "         8           0.7435           0.0002           46.59m\n",
      "         9           0.7431          -0.0014           46.63m\n",
      "        10           0.7443           0.0036           46.51m\n",
      "[CV] END ccp_alpha=0.0024929222914887497, learning_rate=0.09207658460712595, max_depth=5, max_features=0.7, min_samples_leaf=40, min_samples_split=22, min_weight_fraction_leaf=0.0076979909828793, n_estimators=898, n_iter_no_change=7, subsample=0.7483663861762013, tol=0.0009396976523425732, validation_fraction=0.1808120379564417; total time=  39.6s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7625          -0.0000           19.74m\n",
      "         2           0.7620          -0.0202           19.89m\n",
      "         3           0.7624           0.0165           19.67m\n",
      "         4           0.7625           0.0042           19.98m\n",
      "         5           0.7630           0.0230           19.75m\n",
      "         6           0.7629          -0.0070           19.59m\n",
      "         7           0.7626          -0.0103           19.45m\n",
      "[CV] END ccp_alpha=0.00940523264489604, learning_rate=0.08951440421750446, max_depth=9, max_features=log2, min_samples_leaf=44, min_samples_split=10, min_weight_fraction_leaf=0.06756901170392808, n_estimators=672, n_iter_no_change=6, subsample=0.9774080854835687, tol=0.0008873393533809811, validation_fraction=0.12579416277151556; total time=  13.7s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7626          -0.0000           12.23m\n",
      "         2           0.7628           0.0018           13.10m\n",
      "         3           0.7624          -0.0033           13.18m\n",
      "         4           0.7626           0.0017           13.73m\n",
      "         5           0.7628           0.0021           13.81m\n",
      "         6           0.7628           0.0004           13.24m\n",
      "         7           0.7625          -0.0037           13.01m\n",
      "[CV] END ccp_alpha=0.005806866214364547, learning_rate=0.08445655331234861, max_depth=3, max_features=0.3, min_samples_leaf=29, min_samples_split=27, min_weight_fraction_leaf=0.016080805141749865, n_estimators=537, n_iter_no_change=6, subsample=0.9075685593078079, tol=0.0006619612595026006, validation_fraction=0.12242693094605599; total time=  12.0s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7635          -0.0000           29.64m\n",
      "         2           0.7623          -0.0075           30.15m\n",
      "         3           0.7618          -0.0027           28.81m\n",
      "         4           0.7630           0.0073           28.86m\n",
      "         5           0.7629          -0.0009           28.30m\n",
      "         6           0.7629           0.0005           28.55m\n",
      "[CV] END ccp_alpha=0.007121792213475359, learning_rate=0.05744981749936002, max_depth=7, max_features=0.5, min_samples_leaf=12, min_samples_split=16, min_weight_fraction_leaf=0.07209399242521293, n_estimators=839, n_iter_no_change=5, subsample=0.8627620691664697, tol=0.00051881407683876, validation_fraction=0.16363326181858956; total time=  14.0s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7627          -0.0000           43.57m\n",
      "         2           0.7621          -0.0022           43.86m\n",
      "         3           0.7618          -0.0013           43.69m\n",
      "         4           0.7623           0.0021           43.86m\n",
      "         5           0.7626           0.0010           43.76m\n",
      "         6           0.7633           0.0026           43.74m\n",
      "         7           0.7616          -0.0066           43.77m\n",
      "[CV] END ccp_alpha=0.0069602979667497305, learning_rate=0.124012234017873, max_depth=4, max_features=None, min_samples_leaf=27, min_samples_split=75, min_weight_fraction_leaf=0.025416364906973878, n_estimators=689, n_iter_no_change=6, subsample=0.7967652292715801, tol=0.0008586697949246744, validation_fraction=0.11366213314420288; total time=  28.6s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7622          -0.0000           41.54m\n",
      "         2           0.7625           0.0015           41.68m\n",
      "         3           0.7619          -0.0033           41.51m\n",
      "         4           0.7622           0.0019           41.46m\n",
      "         5           0.7627           0.0025           41.37m\n",
      "         6           0.7625          -0.0008           41.52m\n",
      "         7           0.7631           0.0036           41.56m\n",
      "         8           0.7626          -0.0033           41.56m\n",
      "         9           0.7631           0.0030           41.59m\n",
      "        10           0.7623          -0.0045           41.53m\n",
      "[CV] END ccp_alpha=0.00981840888310531, learning_rate=0.17778670041387268, max_depth=4, max_features=None, min_samples_leaf=46, min_samples_split=79, min_weight_fraction_leaf=0.030326551467322285, n_estimators=643, n_iter_no_change=9, subsample=0.8566729780164413, tol=0.0007799935530986108, validation_fraction=0.12158210274968433; total time=  40.9s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7617          -0.0000           16.59m\n",
      "         2           0.7617           0.0002           18.53m\n",
      "         3           0.7626           0.0040           18.94m\n",
      "         4           0.7627           0.0003           19.20m\n",
      "         5           0.7623          -0.0016           19.12m\n",
      "         6           0.7619          -0.0017           18.95m\n",
      "         7           0.7626           0.0031           19.02m\n",
      "         8           0.7619          -0.0032           19.21m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7628          -0.0000           13.12m\n",
      "         2           0.7624          -0.0010           12.91m\n",
      "         3           0.7635           0.0034           13.27m\n",
      "         4           0.7621          -0.0043           13.07m\n",
      "         5           0.7630           0.0028           12.81m\n",
      "         6           0.7626          -0.0013           12.86m\n",
      "         7           0.7631           0.0015           12.87m\n",
      "         8           0.7627          -0.0013           12.76m\n",
      "         9           0.7627           0.0002           12.74m\n",
      "[CV] END ccp_alpha=0.006842330265121569, learning_rate=0.09803049874792026, max_depth=9, max_features=0.5, min_samples_leaf=12, min_samples_split=56, min_weight_fraction_leaf=0.017336465350777208, n_estimators=280, n_iter_no_change=8, subsample=0.7546708263364187, tol=0.0007653614103176525, validation_fraction=0.1425155874491245; total time=  27.3s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7626          -0.0000           11.40m\n",
      "         2           0.7552          -0.0016           12.57m\n",
      "         3           0.7553           0.0028           12.27m\n",
      "         4           0.7488           0.0008           12.09m\n",
      "         5           0.7490           0.0082           11.91m\n",
      "         6           0.7487          -0.0115           11.80m\n",
      "         7           0.7439           0.0287           11.68m\n",
      "         8           0.7434          -0.0178           11.75m\n",
      "         9           0.7434          -0.0022           11.53m\n",
      "        10           0.7434          -0.0004           11.51m\n",
      "        20           0.7395          -0.0124           11.12m\n",
      "        30           0.7399           0.0067           10.81m\n",
      "[CV] END ccp_alpha=0.0020794166286818884, learning_rate=0.1235400655639983, max_depth=7, max_features=log2, min_samples_leaf=30, min_samples_split=53, min_weight_fraction_leaf=0.09394989415641891, n_estimators=469, n_iter_no_change=19, subsample=0.976562270506935, tol=9.849250205191949e-05, validation_fraction=0.11959828624191453; total time=  48.7s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7564           0.0059           46.23m\n",
      "         2           0.7518           0.0066           47.09m\n",
      "         3           0.7478           0.0040           48.19m\n",
      "         4           0.7486           0.0023           48.88m\n",
      "         5           0.7467          -0.0057           48.69m\n",
      "         6           0.7480           0.0041           48.37m\n",
      "         7           0.7474          -0.0019           48.19m\n",
      "         8           0.7460          -0.0042           48.00m\n",
      "         9           0.7481           0.0062           47.69m\n",
      "        10           0.7469          -0.0035           47.66m\n",
      "[CV] END ccp_alpha=0.0024929222914887497, learning_rate=0.09207658460712595, max_depth=5, max_features=0.7, min_samples_leaf=40, min_samples_split=22, min_weight_fraction_leaf=0.0076979909828793, n_estimators=898, n_iter_no_change=7, subsample=0.7483663861762013, tol=0.0009396976523425732, validation_fraction=0.1808120379564417; total time=  34.0s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7624          -0.0000           22.53m\n",
      "         2           0.7621          -0.0113           21.61m\n",
      "         3           0.7627           0.0257           21.00m\n",
      "         4           0.7627          -0.0021           21.35m\n",
      "         5           0.7624          -0.0139           20.62m\n",
      "         6           0.7626           0.0110           20.63m\n",
      "         7           0.7627           0.0026           20.15m\n",
      "[CV] END ccp_alpha=0.00940523264489604, learning_rate=0.08951440421750446, max_depth=9, max_features=log2, min_samples_leaf=44, min_samples_split=10, min_weight_fraction_leaf=0.06756901170392808, n_estimators=672, n_iter_no_change=6, subsample=0.9774080854835687, tol=0.0008873393533809811, validation_fraction=0.12579416277151556; total time=  14.3s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7530           0.0094           30.07m\n",
      "         2           0.7530           0.0004           30.36m\n",
      "         3           0.7532           0.0102           32.20m\n",
      "         4           0.7530          -0.0107           32.19m\n",
      "         5           0.7528          -0.0067           31.80m\n",
      "         6           0.7529           0.0049           31.27m\n",
      "         7           0.7530           0.0051           30.93m\n",
      "         8           0.7529          -0.0060           30.76m\n",
      "         9           0.7530           0.0063           30.68m\n",
      "        10           0.7528          -0.0107           31.52m\n",
      "[CV] END ccp_alpha=0.003492095746126609, learning_rate=0.1551911357740479, max_depth=5, max_features=0.5, min_samples_leaf=28, min_samples_split=63, min_weight_fraction_leaf=0.0779875545857624, n_estimators=827, n_iter_no_change=15, subsample=0.9806904982662842, tol=0.0007953406511139436, validation_fraction=0.16689882547142287; total time=  38.1s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7620          -0.0000           16.06m\n",
      "         2           0.7625           0.0025           16.03m\n",
      "         3           0.7623          -0.0010           16.50m\n",
      "         4           0.7617          -0.0034           16.49m\n",
      "         5           0.7634           0.0100           16.41m\n",
      "         6           0.7624          -0.0061           16.02m\n",
      "         7           0.7623          -0.0004           15.81m\n",
      "         8           0.7625           0.0013           15.93m\n",
      "         9           0.7621          -0.0027           15.95m\n",
      "        10           0.7632           0.0067           15.93m\n",
      "[CV] END ccp_alpha=0.007089109969101186, learning_rate=0.12056399538158155, max_depth=4, max_features=log2, min_samples_leaf=39, min_samples_split=59, min_weight_fraction_leaf=0.08670723185801038, n_estimators=724, n_iter_no_change=16, subsample=0.8534027196582813, tol=0.0005115162946871996, validation_fraction=0.17982951789667753; total time=  23.4s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7627          -0.0000           21.24m\n",
      "         2           0.7624          -0.0030           20.72m\n",
      "         3           0.7628           0.0040           22.60m\n",
      "         4           0.7629           0.0002           22.37m\n",
      "         5           0.7622          -0.0070           22.98m\n",
      "         6           0.7619          -0.0028           22.51m\n",
      "         7           0.7625           0.0063           22.87m\n",
      "         8           0.7621          -0.0046           22.72m\n",
      "         9           0.7627           0.0065           22.45m\n",
      "        10           0.7626          -0.0005           22.31m\n",
      "        20           0.7626          -0.0033           22.62m\n",
      "[CV] END ccp_alpha=0.003988209014447946, learning_rate=0.0967041475161484, max_depth=4, max_features=log2, min_samples_leaf=41, min_samples_split=99, min_weight_fraction_leaf=0.09626484146779252, n_estimators=990, n_iter_no_change=19, subsample=0.9087922618281093, tol=0.00041895294441426993, validation_fraction=0.11732943200708458; total time=  29.4s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7630          -0.0000           56.18m\n",
      "         2           0.7623          -0.0017           55.12m\n",
      "         3           0.7607          -0.0041           54.36m\n",
      "         4           0.7622           0.0037           54.90m\n",
      "         5           0.7624           0.0006           55.03m\n",
      "         6           0.7608          -0.0038           55.27m\n",
      "         7           0.7615           0.0015           55.13m\n",
      "[CV] END ccp_alpha=0.00933436308079483, learning_rate=0.11020797678305184, max_depth=7, max_features=0.7, min_samples_leaf=8, min_samples_split=25, min_weight_fraction_leaf=0.007056874740042985, n_estimators=958, n_iter_no_change=6, subsample=0.7079533931624865, tol=0.0005957755812734634, validation_fraction=0.19402302414249578; total time=  25.7s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7556           0.0069           30.54m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7623          -0.0000           12.15m\n",
      "         2           0.7547           0.0189           13.08m\n",
      "         3           0.7460           0.0005           12.35m\n",
      "         4           0.7410           0.0031           12.24m\n",
      "         5           0.7387           0.0023           12.31m\n",
      "         6           0.7351           0.0090           12.20m\n",
      "         7           0.7315           0.0018           12.22m\n",
      "         8           0.7293          -0.0005           12.20m\n",
      "         9           0.7272           0.0019           12.23m\n",
      "        10           0.7257           0.0098           12.32m\n",
      "        20           0.7228          -0.0013           12.39m\n",
      "        30           0.7225          -0.0003           12.38m\n",
      "[CV] END ccp_alpha=0.00046450412719997725, learning_rate=0.1315089703802877, max_depth=7, max_features=sqrt, min_samples_leaf=43, min_samples_split=27, min_weight_fraction_leaf=0.09488855372533334, n_estimators=515, n_iter_no_change=18, subsample=0.9425192044349383, tol=0.0003146137691733707, validation_fraction=0.10976721140063839; total time=  47.6s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7630          -0.0000            7.42m\n",
      "         2           0.7633           0.0011            7.42m\n",
      "         3           0.7621          -0.0046            7.23m\n",
      "         4           0.7626           0.0020            7.07m\n",
      "         5           0.7624          -0.0010            6.90m\n",
      "         6           0.7612          -0.0045            6.90m\n",
      "         7           0.7629           0.0066            6.88m\n",
      "         8           0.7632           0.0013            6.88m\n",
      "         9           0.7628          -0.0016            6.82m\n",
      "        10           0.7632           0.0013            6.85m\n",
      "[CV] END ccp_alpha=0.009263008785133489, learning_rate=0.1402154051003889, max_depth=6, max_features=sqrt, min_samples_leaf=12, min_samples_split=21, min_weight_fraction_leaf=0.03308980248526492, n_estimators=247, n_iter_no_change=11, subsample=0.7932946965146986, tol=0.0003351833220267471, validation_fraction=0.1729606178338064; total time=  22.4s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7615          -0.0000           31.80m\n",
      "         2           0.7621           0.0023           31.61m\n",
      "         3           0.7621           0.0002           31.74m\n",
      "         4           0.7622           0.0001           32.15m\n",
      "         5           0.7632           0.0042           32.07m\n",
      "         6           0.7632          -0.0003           32.67m\n",
      "[CV] END ccp_alpha=0.0052273282938199404, learning_rate=0.09550820367170992, max_depth=4, max_features=0.5, min_samples_leaf=17, min_samples_split=60, min_weight_fraction_leaf=0.0031429185686734254, n_estimators=942, n_iter_no_change=5, subsample=0.794306794322898, tol=0.0005185706911647028, validation_fraction=0.1907566473926093; total time=  14.1s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7547           0.0088           18.80m\n",
      "         2           0.7466           0.0027           19.11m\n",
      "         3           0.7469           0.0016           19.42m\n",
      "         4           0.7466          -0.0016           19.51m\n",
      "         5           0.7465          -0.0004           19.15m\n",
      "         6           0.7458          -0.0033           19.01m\n",
      "         7           0.7464           0.0030           18.97m\n",
      "         8           0.7467           0.0012           19.28m\n",
      "         9           0.7471           0.0017           19.36m\n",
      "        10           0.7474           0.0017           19.24m\n",
      "[CV] END ccp_alpha=0.002721322493846353, learning_rate=0.13953802410827248, max_depth=3, max_features=0.5, min_samples_leaf=17, min_samples_split=12, min_weight_fraction_leaf=0.0006952130531190704, n_estimators=655, n_iter_no_change=15, subsample=0.8252233009446337, tol=0.00023210781047073025, validation_fraction=0.11198653673336828; total time=  31.5s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7622          -0.0000           28.96m\n",
      "         2           0.7625           0.0089           28.30m\n",
      "         3           0.7622          -0.0081           28.11m\n",
      "         4           0.7627           0.0162           27.88m\n",
      "         5           0.7624          -0.0099           28.15m\n",
      "         6           0.7626           0.0068           28.84m\n",
      "         7           0.7622          -0.0136           28.77m\n",
      "         8           0.7624           0.0047           29.18m\n",
      "         9           0.7628           0.0148           29.01m\n",
      "        10           0.7623          -0.0178           29.01m\n",
      "[CV] END ccp_alpha=0.006599840460341791, learning_rate=0.17344444004024318, max_depth=3, max_features=0.5, min_samples_leaf=6, min_samples_split=10, min_weight_fraction_leaf=0.009310276780589922, n_estimators=851, n_iter_no_change=9, subsample=0.970125417148999, tol=0.000643101457273268, validation_fraction=0.1339029791048701; total time=  21.8s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7544           0.0078           25.83m\n",
      "         2           0.7482           0.0104           24.70m\n",
      "         3           0.7482           0.0001           26.12m\n",
      "         4           0.7481          -0.0007           26.40m\n",
      "         5           0.7482           0.0008           26.07m\n",
      "         6           0.7476          -0.0046           26.12m\n",
      "         7           0.7483           0.0053           26.02m\n",
      "         8           0.7489           0.0055           26.04m\n",
      "         9           0.7485          -0.0038           25.94m\n",
      "        10           0.7477          -0.0069           25.84m\n",
      "        20           0.7478          -0.0014           24.50m\n",
      "[CV] END ccp_alpha=0.0025046181860558414, learning_rate=0.12797416951210877, max_depth=8, max_features=0.7, min_samples_leaf=12, min_samples_split=36, min_weight_fraction_leaf=0.04343943655104287, n_estimators=476, n_iter_no_change=18, subsample=0.8935310086091695, tol=0.0006789240596630997, validation_fraction=0.1864167565071903; total time= 1.1min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7624          -0.0000           10.84m\n",
      "         2           0.7618          -0.0025           10.60m\n",
      "         3           0.7614          -0.0015           10.59m\n",
      "         4           0.7630           0.0061           10.43m\n",
      "         5           0.7622          -0.0031           10.18m\n",
      "         6           0.7623           0.0003            9.93m\n",
      "[CV] END ccp_alpha=0.005660372104940763, learning_rate=0.041729289528498206, max_depth=8, max_features=sqrt, min_samples_leaf=33, min_samples_split=87, min_weight_fraction_leaf=0.009179906581344188, n_estimators=246, n_iter_no_change=5, subsample=0.7934239928173882, tol=0.0009895105286215086, validation_fraction=0.11753302698893386; total time=  16.1s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7618          -0.0000           18.35m\n",
      "         2           0.7616          -0.0009           19.21m\n",
      "         3           0.7630           0.0065           18.79m\n",
      "         4           0.7636           0.0025           18.28m\n",
      "         5           0.7619          -0.0079           18.62m\n",
      "         6           0.7631           0.0055           19.30m\n",
      "         7           0.7620          -0.0049           19.01m\n",
      "         8           0.7634           0.0063           19.01m\n",
      "         9           0.7622          -0.0054           18.86m\n",
      "        10           0.7625           0.0013           18.89m\n",
      "[CV] END ccp_alpha=0.00575474177875879, learning_rate=0.08763398524130438, max_depth=6, max_features=sqrt, min_samples_leaf=37, min_samples_split=70, min_weight_fraction_leaf=0.0545616789315935, n_estimators=812, n_iter_no_change=16, subsample=0.8158307913402323, tol=0.0009711905638239142, validation_fraction=0.1905350641956064; total time=  25.0s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7623          -0.0000            7.26m\n",
      "         2           0.7626           0.0064            6.90m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7532           0.0093           12.24m\n",
      "         2           0.7453           0.0063           12.56m\n",
      "         3           0.7406           0.0051           12.49m\n",
      "         4           0.7376           0.0120           12.43m\n",
      "         5           0.7337          -0.0048           12.72m\n",
      "         6           0.7299           0.0011           12.57m\n",
      "         7           0.7274          -0.0035           12.47m\n",
      "         8           0.7276           0.0038           12.62m\n",
      "         9           0.7278           0.0031           12.52m\n",
      "        10           0.7276          -0.0029           12.41m\n",
      "        20           0.7237           0.0117           12.40m\n",
      "        30           0.7237          -0.0010           12.43m\n",
      "[CV] END ccp_alpha=0.00046450412719997725, learning_rate=0.1315089703802877, max_depth=7, max_features=sqrt, min_samples_leaf=43, min_samples_split=27, min_weight_fraction_leaf=0.09488855372533334, n_estimators=515, n_iter_no_change=18, subsample=0.9425192044349383, tol=0.0003146137691733707, validation_fraction=0.10976721140063839; total time=  56.5s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7626          -0.0000           18.48m\n",
      "         2           0.7625          -0.0008           19.66m\n",
      "         3           0.7626           0.0011           20.10m\n",
      "         4           0.7629           0.0017           19.65m\n",
      "         5           0.7628          -0.0008           19.51m\n",
      "         6           0.7629           0.0006           19.35m\n",
      "         7           0.7624          -0.0034           19.22m\n",
      "         8           0.7620          -0.0022           19.18m\n",
      "         9           0.7630           0.0066           19.22m\n",
      "        10           0.7629          -0.0008           19.03m\n",
      "[CV] END ccp_alpha=0.006375574713552132, learning_rate=0.18744254851526532, max_depth=3, max_features=0.3, min_samples_leaf=41, min_samples_split=56, min_weight_fraction_leaf=0.07132447872229951, n_estimators=968, n_iter_no_change=9, subsample=0.8683831592708489, tol=0.000780967179954561, validation_fraction=0.1493795596364391; total time=  13.2s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7613          -0.0000           31.31m\n",
      "         2           0.7626           0.0051           31.50m\n",
      "         3           0.7617          -0.0034           31.66m\n",
      "         4           0.7627           0.0040           32.18m\n",
      "         5           0.7630           0.0009           32.07m\n",
      "         6           0.7626          -0.0015           31.97m\n",
      "[CV] END ccp_alpha=0.0052273282938199404, learning_rate=0.09550820367170992, max_depth=4, max_features=0.5, min_samples_leaf=17, min_samples_split=60, min_weight_fraction_leaf=0.0031429185686734254, n_estimators=942, n_iter_no_change=5, subsample=0.794306794322898, tol=0.0005185706911647028, validation_fraction=0.1907566473926093; total time=  13.6s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7627          -0.0000           14.99m\n",
      "         2           0.7628           0.0001           14.72m\n",
      "         3           0.7625          -0.0008           14.70m\n",
      "         4           0.7616          -0.0023           14.35m\n",
      "         5           0.7646           0.0083           13.91m\n",
      "         6           0.7626          -0.0055           14.16m\n",
      "         7           0.7615          -0.0032           14.26m\n",
      "         8           0.7620           0.0015           14.19m\n",
      "         9           0.7625           0.0012           14.08m\n",
      "        10           0.7625           0.0002           14.14m\n",
      "[CV] END ccp_alpha=0.006334037565104235, learning_rate=0.18429211803754356, max_depth=6, max_features=0.5, min_samples_leaf=48, min_samples_split=93, min_weight_fraction_leaf=0.08925589984899779, n_estimators=530, n_iter_no_change=14, subsample=0.736626386410202, tol=0.0003662978380769749, validation_fraction=0.19068284415457543; total time=  26.0s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7597           0.0030           22.00m\n",
      "         2           0.7601           0.0066           21.68m\n",
      "         3           0.7593          -0.0136           21.77m\n",
      "         4           0.7595           0.0033           21.99m\n",
      "         5           0.7566           0.0027           22.10m\n",
      "         6           0.7571           0.0079           22.41m\n",
      "         7           0.7541          -0.0051           22.18m\n",
      "         8           0.7537          -0.0055           22.23m\n",
      "         9           0.7538           0.0020           22.31m\n",
      "        10           0.7538          -0.0008           22.37m\n",
      "[CV] END ccp_alpha=0.0032078006497173583, learning_rate=0.04730370207997085, max_depth=7, max_features=0.3, min_samples_leaf=24, min_samples_split=68, min_weight_fraction_leaf=0.022024104756554832, n_estimators=545, n_iter_no_change=7, subsample=0.9428503138419145, tol=0.0003586659872917294, validation_fraction=0.10961765510914208; total time=  36.3s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7563           0.0062           21.21m\n",
      "         2           0.7508          -0.0105           20.58m\n",
      "         3           0.7511           0.0144           18.92m\n",
      "         4           0.7463          -0.0013           17.77m\n",
      "         5           0.7463          -0.0001           17.96m\n",
      "         6           0.7421           0.0123           17.71m\n",
      "         7           0.7421           0.0007           17.46m\n",
      "         8           0.7420          -0.0059           17.48m\n",
      "         9           0.7422           0.0085           17.21m\n",
      "        10           0.7417          -0.0182           17.25m\n",
      "        20           0.7420           0.0131           16.80m\n",
      "[CV] END ccp_alpha=0.002301852682415553, learning_rate=0.10983867597695046, max_depth=6, max_features=0.3, min_samples_leaf=21, min_samples_split=53, min_weight_fraction_leaf=0.09404585843529144, n_estimators=676, n_iter_no_change=18, subsample=0.9744593170661344, tol=0.0003801587002554444, validation_fraction=0.10154566165288675; total time=  38.2s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7626          -0.0000           34.18m\n",
      "         2           0.7625          -0.0097           33.76m\n",
      "         3           0.7625          -0.0031           33.65m\n",
      "         4           0.7623          -0.0253           33.72m\n",
      "         5           0.7627           0.0445           33.96m\n",
      "         6           0.7625          -0.0199           34.47m\n",
      "         7           0.7625           0.0019           35.04m\n",
      "         8           0.7627           0.0160           35.28m\n",
      "         9           0.7623          -0.0343           35.29m\n",
      "        10           0.7626           0.0230           35.28m\n",
      "[CV] END ccp_alpha=0.0062289047581900025, learning_rate=0.0270694929987536, max_depth=7, max_features=0.5, min_samples_leaf=34, min_samples_split=56, min_weight_fraction_leaf=0.06995122107671939, n_estimators=855, n_iter_no_change=17, subsample=0.9908610601342476, tol=0.0007245951041799522, validation_fraction=0.10410675167678758; total time=  45.9s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7555           0.0071           30.51m\n",
      "         2           0.7501           0.0069           29.13m\n",
      "         3           0.7501          -0.0005           28.58m\n",
      "         4           0.7456           0.0116           27.55m\n",
      "         5           0.7449          -0.0104           27.68m\n",
      "         6           0.7456           0.0106           27.78m\n",
      "         7           0.7451          -0.0069           27.85m\n",
      "         8           0.7458           0.0108           28.08m\n",
      "         9           0.7453          -0.0086           27.97m\n",
      "        10           0.7453           0.0001           28.03m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7497           0.0128           20.23m\n",
      "         2           0.7418           0.0140           19.20m\n",
      "         3           0.7352           0.0016           18.93m\n",
      "         4           0.7322           0.0090           18.76m\n",
      "         5           0.7301           0.0040           19.06m\n",
      "         6           0.7273           0.0019           19.27m\n",
      "         7           0.7249          -0.0039           19.36m\n",
      "         8           0.7256           0.0052           19.47m\n",
      "         9           0.7252          -0.0030           19.73m\n",
      "        10           0.7250          -0.0013           19.81m\n",
      "        20           0.7237           0.0035           19.60m\n",
      "[CV] END ccp_alpha=0.0005641157902710026, learning_rate=0.15439975445336496, max_depth=8, max_features=None, min_samples_leaf=6, min_samples_split=73, min_weight_fraction_leaf=0.09922115592912176, n_estimators=360, n_iter_no_change=16, subsample=0.8834959481464842, tol=1.706630521971741e-05, validation_fraction=0.10230624250414158; total time= 1.7min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7618          -0.0000            6.33m\n",
      "         2           0.7625           0.0038            6.33m\n",
      "         3           0.7632           0.0033            6.19m\n",
      "         4           0.7624          -0.0037            6.29m\n",
      "         5           0.7635           0.0053            6.18m\n",
      "         6           0.7625          -0.0052            6.07m\n",
      "         7           0.7622          -0.0011            6.14m\n",
      "         8           0.7634           0.0061            6.00m\n",
      "         9           0.7624          -0.0051            5.99m\n",
      "        10           0.7624           0.0002            5.94m\n",
      "[CV] END ccp_alpha=0.005026790232288615, learning_rate=0.02029575024999787, max_depth=7, max_features=sqrt, min_samples_leaf=5, min_samples_split=28, min_weight_fraction_leaf=0.06807054515547668, n_estimators=252, n_iter_no_change=16, subsample=0.8343349493719274, tol=0.000562893089071328, validation_fraction=0.15926967238793938; total time=  26.6s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7626          -0.0000           12.20m\n",
      "         2           0.7628           0.0018           12.97m\n",
      "         3           0.7624          -0.0033           13.26m\n",
      "         4           0.7626           0.0017           13.58m\n",
      "         5           0.7628           0.0021           13.34m\n",
      "         6           0.7628           0.0004           12.88m\n",
      "         7           0.7625          -0.0037           12.76m\n",
      "[CV] END ccp_alpha=0.005806866214364547, learning_rate=0.08445655331234861, max_depth=3, max_features=0.3, min_samples_leaf=29, min_samples_split=27, min_weight_fraction_leaf=0.016080805141749865, n_estimators=537, n_iter_no_change=6, subsample=0.9075685593078079, tol=0.0006619612595026006, validation_fraction=0.12242693094605599; total time=  11.4s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7548           0.0083           24.99m\n",
      "         2           0.7484           0.0059           25.61m\n",
      "         3           0.7477          -0.0061           26.72m\n",
      "         4           0.7480           0.0025           27.01m\n",
      "         5           0.7482           0.0024           26.73m\n",
      "         6           0.7484           0.0016           26.32m\n",
      "         7           0.7476          -0.0071           26.04m\n",
      "         8           0.7480           0.0037           26.00m\n",
      "         9           0.7483           0.0025           25.72m\n",
      "        10           0.7481          -0.0017           25.67m\n",
      "        20           0.7480           0.0000           24.73m\n",
      "[CV] END ccp_alpha=0.0025046181860558414, learning_rate=0.12797416951210877, max_depth=8, max_features=0.7, min_samples_leaf=12, min_samples_split=36, min_weight_fraction_leaf=0.04343943655104287, n_estimators=476, n_iter_no_change=18, subsample=0.8935310086091695, tol=0.0006789240596630997, validation_fraction=0.1864167565071903; total time= 1.1min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7624          -0.0000           10.34m\n",
      "         2           0.7618          -0.0025           10.72m\n",
      "         3           0.7614          -0.0015           10.34m\n",
      "         4           0.7630           0.0061           10.24m\n",
      "         5           0.7622          -0.0031           10.00m\n",
      "         6           0.7623           0.0003            9.81m\n",
      "[CV] END ccp_alpha=0.005660372104940763, learning_rate=0.041729289528498206, max_depth=8, max_features=sqrt, min_samples_leaf=33, min_samples_split=87, min_weight_fraction_leaf=0.009179906581344188, n_estimators=246, n_iter_no_change=5, subsample=0.7934239928173882, tol=0.0009895105286215086, validation_fraction=0.11753302698893386; total time=  16.2s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7618          -0.0000           19.63m\n",
      "         2           0.7616          -0.0009           19.60m\n",
      "         3           0.7630           0.0065           19.72m\n",
      "         4           0.7636           0.0025           19.19m\n",
      "         5           0.7619          -0.0079           19.39m\n",
      "         6           0.7631           0.0055           19.78m\n",
      "         7           0.7620          -0.0049           19.43m\n",
      "         8           0.7634           0.0063           19.45m\n",
      "         9           0.7622          -0.0054           19.17m\n",
      "        10           0.7625           0.0013           19.21m\n",
      "[CV] END ccp_alpha=0.00575474177875879, learning_rate=0.08763398524130438, max_depth=6, max_features=sqrt, min_samples_leaf=37, min_samples_split=70, min_weight_fraction_leaf=0.0545616789315935, n_estimators=812, n_iter_no_change=16, subsample=0.8158307913402323, tol=0.0009711905638239142, validation_fraction=0.1905350641956064; total time=  25.5s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7623          -0.0000            7.44m\n",
      "         2           0.7626           0.0064            6.94m\n",
      "         3           0.7625          -0.0027            6.78m\n",
      "         4           0.7623          -0.0055            6.74m\n",
      "         5           0.7625           0.0049            6.80m\n",
      "         6           0.7629           0.0115            6.80m\n",
      "         7           0.7624          -0.0121            6.76m\n",
      "         8           0.7626           0.0027            6.75m\n",
      "         9           0.7624          -0.0037            6.63m\n",
      "        10           0.7625           0.0019            6.57m\n",
      "[CV] END ccp_alpha=0.007506147516408584, learning_rate=0.17136694785345283, max_depth=3, max_features=0.3, min_samples_leaf=40, min_samples_split=91, min_weight_fraction_leaf=0.02500164492161047, n_estimators=295, n_iter_no_change=12, subsample=0.9601349821629166, tol=0.0005718666921437737, validation_fraction=0.12385968597903402; total time=  19.0s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7617          -0.0000           20.28m\n",
      "         2           0.7632           0.0059           19.29m\n",
      "         3           0.7616          -0.0061           19.42m\n",
      "         4           0.7622           0.0021           19.12m\n",
      "         5           0.7625           0.0014           19.34m\n",
      "         6           0.7634           0.0036           19.08m\n",
      "         7           0.7632          -0.0009           19.21m\n",
      "         8           0.7620          -0.0048           19.44m\n",
      "         9           0.7637           0.0067           19.61m\n",
      "        10           0.7628          -0.0036           19.57m\n",
      "[CV] END ccp_alpha=0.006798447799002459, learning_rate=0.15798175208947493, max_depth=5, max_features=sqrt, min_samples_leaf=34, min_samples_split=26, min_weight_fraction_leaf=0.053432747353056344, n_estimators=795, n_iter_no_change=13, subsample=0.7960148803091834, tol=0.0009055232284962006, validation_fraction=0.13892016787341632; total time=  22.3s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7583           0.0050           26.44m\n",
      "         2           0.7532           0.0014           26.56m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7500           0.0121           35.91m\n",
      "         2           0.7505           0.0020           35.29m\n",
      "         3           0.7498          -0.0029           35.86m\n",
      "         4           0.7499           0.0004           35.23m\n",
      "         5           0.7500           0.0005           35.28m\n",
      "         6           0.7509           0.0037           35.49m\n",
      "         7           0.7497          -0.0047           35.58m\n",
      "         8           0.7508           0.0043           35.40m\n",
      "         9           0.7506          -0.0008           36.24m\n",
      "        10           0.7506          -0.0000           36.21m\n",
      "[CV] END ccp_alpha=0.003745401188473625, learning_rate=0.20014286128198325, max_depth=5, max_features=0.7, min_samples_leaf=25, min_samples_split=92, min_weight_fraction_leaf=0.00999749158180029, n_estimators=658, n_iter_no_change=12, subsample=0.8001125833417065, tol=0.00015286681792194077, validation_fraction=0.1650888472948853; total time=  45.1s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7532           0.0096           21.08m\n",
      "         2           0.7467           0.0052           20.49m\n",
      "         3           0.7408           0.0036           21.00m\n",
      "         4           0.7358           0.0047           21.31m\n",
      "         5           0.7329           0.0038           21.42m\n",
      "         6           0.7298           0.0072           21.12m\n",
      "         7           0.7260          -0.0070           21.30m\n",
      "         8           0.7248           0.0132           21.38m\n",
      "         9           0.7234           0.0038           21.32m\n",
      "        10           0.7214          -0.0021           21.27m\n",
      "        20           0.7141           0.0017           21.23m\n",
      "[CV] END ccp_alpha=0.00015636406741193932, learning_rate=0.09468029614127392, max_depth=3, max_features=0.5, min_samples_leaf=12, min_samples_split=97, min_weight_fraction_leaf=0.0014079822715084456, n_estimators=698, n_iter_no_change=5, subsample=0.9134025858245949, tol=0.0008001755405312057, validation_fraction=0.16059599747810116; total time=  50.5s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7514           0.0110            7.60m\n",
      "         2           0.7511          -0.0010            8.33m\n",
      "         3           0.7526           0.0053            8.17m\n",
      "         4           0.7511          -0.0054            8.42m\n",
      "         5           0.7521           0.0035            8.45m\n",
      "         6           0.7507          -0.0051            8.37m\n",
      "         7           0.7508           0.0003            8.34m\n",
      "         8           0.7517           0.0034            8.32m\n",
      "         9           0.7515          -0.0006            8.33m\n",
      "        10           0.7518           0.0010            8.16m\n",
      "[CV] END ccp_alpha=0.0033761517140362797, learning_rate=0.19858194078250385, max_depth=8, max_features=sqrt, min_samples_leaf=16, min_samples_split=48, min_weight_fraction_leaf=0.04972485058923855, n_estimators=312, n_iter_no_change=9, subsample=0.7854521483132403, tol=4.68869473545328e-05, validation_fraction=0.1609564333979897; total time=  17.8s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7622          -0.0000           26.78m\n",
      "         2           0.7625           0.0089           27.68m\n",
      "         3           0.7622          -0.0081           27.89m\n",
      "         4           0.7627           0.0162           27.76m\n",
      "         5           0.7624          -0.0099           27.76m\n",
      "         6           0.7626           0.0068           28.47m\n",
      "         7           0.7622          -0.0136           28.20m\n",
      "         8           0.7624           0.0047           28.34m\n",
      "         9           0.7628           0.0148           28.58m\n",
      "        10           0.7623          -0.0178           28.55m\n",
      "[CV] END ccp_alpha=0.006599840460341791, learning_rate=0.17344444004024318, max_depth=3, max_features=0.5, min_samples_leaf=6, min_samples_split=10, min_weight_fraction_leaf=0.009310276780589922, n_estimators=851, n_iter_no_change=9, subsample=0.970125417148999, tol=0.000643101457273268, validation_fraction=0.1339029791048701; total time=  21.8s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7619          -0.0000           30.14m\n",
      "         2           0.7626           0.0044           30.72m\n",
      "         3           0.7628           0.0014           29.35m\n",
      "         4           0.7623          -0.0032           28.60m\n",
      "         5           0.7630           0.0043           28.71m\n",
      "         6           0.7628          -0.0017           29.15m\n",
      "[CV] END ccp_alpha=0.007121792213475359, learning_rate=0.05744981749936002, max_depth=7, max_features=0.5, min_samples_leaf=12, min_samples_split=16, min_weight_fraction_leaf=0.07209399242521293, n_estimators=839, n_iter_no_change=5, subsample=0.8627620691664697, tol=0.00051881407683876, validation_fraction=0.16363326181858956; total time=  13.9s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7639          -0.0000           10.51m\n",
      "         2           0.7635          -0.0014           10.27m\n",
      "         3           0.7626          -0.0026           10.16m\n",
      "         4           0.7628           0.0004           10.10m\n",
      "         5           0.7624          -0.0011           10.22m\n",
      "         6           0.7614          -0.0032           10.10m\n",
      "         7           0.7625           0.0035           10.00m\n",
      "         8           0.7631           0.0017            9.95m\n",
      "[CV] END ccp_alpha=0.009283185625877254, learning_rate=0.09563682966346286, max_depth=7, max_features=0.3, min_samples_leaf=37, min_samples_split=72, min_weight_fraction_leaf=0.030569701928718187, n_estimators=360, n_iter_no_change=7, subsample=0.7508478240058277, tol=0.0005668012624583502, validation_fraction=0.1936154774160781; total time=  15.4s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7621          -0.0000           51.04m\n",
      "         2           0.7627           0.0059           50.73m\n",
      "         3           0.7623          -0.0038           49.29m\n",
      "         4           0.7627           0.0031           49.31m\n",
      "         5           0.7623          -0.0037           49.92m\n",
      "         6           0.7624           0.0011           49.88m\n",
      "         7           0.7629           0.0047           49.35m\n",
      "         8           0.7626          -0.0023           49.10m\n",
      "         9           0.7625          -0.0010           48.61m\n",
      "        10           0.7623          -0.0018           48.65m\n",
      "[CV] END ccp_alpha=0.006499639307777652, learning_rate=0.1503933754515407, max_depth=8, max_features=0.5, min_samples_leaf=27, min_samples_split=24, min_weight_fraction_leaf=0.0375582952639944, n_estimators=999, n_iter_no_change=11, subsample=0.9016078405885598, tol=0.00033815266747473194, validation_fraction=0.11550416167277443; total time=  36.9s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7586           0.0039           53.67m\n",
      "         2           0.7552           0.0041           54.90m\n",
      "         3           0.7526           0.0054           53.99m\n",
      "         4           0.7498           0.0038           52.26m\n",
      "         5           0.7473           0.0025           51.71m\n",
      "         6           0.7443          -0.0004           50.58m\n",
      "         7           0.7413          -0.0034           50.27m\n",
      "         8           0.7411           0.0115           49.79m\n",
      "         9           0.7396           0.0017           50.00m\n",
      "        10           0.7362          -0.0065           49.41m\n",
      "        20           0.7369          -0.0016           48.26m\n",
      "[CV] END ccp_alpha=0.0015643704267108605, learning_rate=0.06004857963291907, max_depth=8, max_features=None, min_samples_leaf=29, min_samples_split=10, min_weight_fraction_leaf=0.09548652806631941, n_estimators=903, n_iter_no_change=19, subsample=0.8307018696033672, tol=0.0007400393165618186, validation_fraction=0.10477161276916488; total time= 1.6min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7539           0.0081           12.06m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7496           0.0126           19.90m\n",
      "         2           0.7417           0.0143           19.92m\n",
      "         3           0.7351           0.0015           19.42m\n",
      "         4           0.7321           0.0087           19.10m\n",
      "         5           0.7301           0.0049           19.32m\n",
      "         6           0.7273           0.0019           19.40m\n",
      "         7           0.7251          -0.0043           19.43m\n",
      "         8           0.7237           0.0063           19.58m\n",
      "         9           0.7233          -0.0027           19.80m\n",
      "        10           0.7233           0.0000           19.84m\n",
      "        20           0.7238           0.0028           19.67m\n",
      "[CV] END ccp_alpha=0.0005641157902710026, learning_rate=0.15439975445336496, max_depth=8, max_features=None, min_samples_leaf=6, min_samples_split=73, min_weight_fraction_leaf=0.09922115592912176, n_estimators=360, n_iter_no_change=16, subsample=0.8834959481464842, tol=1.706630521971741e-05, validation_fraction=0.10230624250414158; total time= 1.4min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7548           0.0087           19.99m\n",
      "         2           0.7466           0.0027           20.44m\n",
      "         3           0.7470           0.0016           20.45m\n",
      "         4           0.7467          -0.0014           20.06m\n",
      "         5           0.7466          -0.0006           19.64m\n",
      "         6           0.7459          -0.0032           19.41m\n",
      "         7           0.7465           0.0029           19.29m\n",
      "         8           0.7469           0.0017           19.52m\n",
      "         9           0.7471           0.0013           19.56m\n",
      "        10           0.7474           0.0013           19.35m\n",
      "[CV] END ccp_alpha=0.002721322493846353, learning_rate=0.13953802410827248, max_depth=3, max_features=0.5, min_samples_leaf=17, min_samples_split=12, min_weight_fraction_leaf=0.0006952130531190704, n_estimators=655, n_iter_no_change=15, subsample=0.8252233009446337, tol=0.00023210781047073025, validation_fraction=0.11198653673336828; total time=  31.3s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7623          -0.0000           28.98m\n",
      "         2           0.7622          -0.0031           29.19m\n",
      "         3           0.7625           0.0095           28.90m\n",
      "         4           0.7624          -0.0027           29.15m\n",
      "         5           0.7628           0.0126           29.42m\n",
      "         6           0.7626          -0.0042           28.96m\n",
      "         7           0.7627           0.0015           29.53m\n",
      "         8           0.7623          -0.0112           29.31m\n",
      "         9           0.7627           0.0112           29.29m\n",
      "        10           0.7625          -0.0054           29.15m\n",
      "[CV] END ccp_alpha=0.006599840460341791, learning_rate=0.17344444004024318, max_depth=3, max_features=0.5, min_samples_leaf=6, min_samples_split=10, min_weight_fraction_leaf=0.009310276780589922, n_estimators=851, n_iter_no_change=9, subsample=0.970125417148999, tol=0.000643101457273268, validation_fraction=0.1339029791048701; total time=  22.4s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7563           0.0061           19.43m\n",
      "         2           0.7507          -0.0102           19.26m\n",
      "         3           0.7511           0.0150           17.57m\n",
      "         4           0.7462          -0.0012           17.28m\n",
      "         5           0.7462           0.0001           17.54m\n",
      "         6           0.7420           0.0115           17.50m\n",
      "         7           0.7420           0.0006           17.42m\n",
      "         8           0.7419          -0.0068           17.48m\n",
      "         9           0.7421           0.0095           17.22m\n",
      "        10           0.7416          -0.0188           17.26m\n",
      "        20           0.7420           0.0138           17.13m\n",
      "[CV] END ccp_alpha=0.002301852682415553, learning_rate=0.10983867597695046, max_depth=6, max_features=0.3, min_samples_leaf=21, min_samples_split=53, min_weight_fraction_leaf=0.09404585843529144, n_estimators=676, n_iter_no_change=18, subsample=0.9744593170661344, tol=0.0003801587002554444, validation_fraction=0.10154566165288675; total time=  39.2s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7621          -0.0000           43.36m\n",
      "         2           0.7628           0.0042           43.47m\n",
      "         3           0.7629           0.0010           42.77m\n",
      "         4           0.7631           0.0011           42.42m\n",
      "         5           0.7631          -0.0000           42.27m\n",
      "         6           0.7630          -0.0009           42.38m\n",
      "         7           0.7625          -0.0030           42.40m\n",
      "         8           0.7623          -0.0009           42.24m\n",
      "         9           0.7628           0.0027           42.20m\n",
      "        10           0.7619          -0.0053           42.03m\n",
      "[CV] END ccp_alpha=0.00981840888310531, learning_rate=0.17778670041387268, max_depth=4, max_features=None, min_samples_leaf=46, min_samples_split=79, min_weight_fraction_leaf=0.030326551467322285, n_estimators=643, n_iter_no_change=9, subsample=0.8566729780164413, tol=0.0007799935530986108, validation_fraction=0.12158210274968433; total time=  41.0s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7634          -0.0000           56.77m\n",
      "         2           0.7627          -0.0015           56.84m\n",
      "         3           0.7633           0.0015           58.40m\n",
      "         4           0.7625          -0.0019           58.63m\n",
      "         5           0.7620          -0.0013           58.40m\n",
      "         6           0.7620           0.0001           58.45m\n",
      "         7           0.7632           0.0028           58.34m\n",
      "[CV] END ccp_alpha=0.00933436308079483, learning_rate=0.11020797678305184, max_depth=7, max_features=0.7, min_samples_leaf=8, min_samples_split=25, min_weight_fraction_leaf=0.007056874740042985, n_estimators=958, n_iter_no_change=6, subsample=0.7079533931624865, tol=0.0005957755812734634, validation_fraction=0.19402302414249578; total time=  27.3s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7623          -0.0000           22.00m\n",
      "         2           0.7611          -0.0046           20.16m\n",
      "         3           0.7624           0.0050           20.06m\n",
      "         4           0.7615          -0.0034           19.65m\n",
      "         5           0.7628           0.0049           19.27m\n",
      "         6           0.7617          -0.0039           19.55m\n",
      "         7           0.7628           0.0040           19.56m\n",
      "         8           0.7627          -0.0004           19.41m\n",
      "         9           0.7622          -0.0017           19.28m\n",
      "        10           0.7641           0.0074           19.22m\n",
      "[CV] END ccp_alpha=0.006798447799002459, learning_rate=0.15798175208947493, max_depth=5, max_features=sqrt, min_samples_leaf=34, min_samples_split=26, min_weight_fraction_leaf=0.053432747353056344, n_estimators=795, n_iter_no_change=13, subsample=0.7960148803091834, tol=0.0009055232284962006, validation_fraction=0.13892016787341632; total time=  22.1s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7488           0.0137           14.32m\n",
      "         2           0.7406           0.0044           13.53m\n",
      "         3           0.7338           0.0123           13.29m\n",
      "         4           0.7281           0.0091           13.08m\n",
      "         5           0.7232          -0.0030           12.70m\n",
      "         6           0.7208           0.0051           12.83m\n",
      "         7           0.7205           0.0039           12.60m\n",
      "         8           0.7177          -0.0081           12.63m\n",
      "         9           0.7188           0.0141           12.65m\n",
      "        10           0.7168          -0.0070           12.43m\n",
      "        20           0.7147          -0.0021           13.04m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7623          -0.0000           11.61m\n",
      "         2           0.7546           0.0191           12.83m\n",
      "         3           0.7460           0.0006           12.39m\n",
      "         4           0.7410           0.0030           12.27m\n",
      "         5           0.7387           0.0022           12.26m\n",
      "         6           0.7352           0.0097           12.18m\n",
      "         7           0.7350          -0.0017           12.12m\n",
      "         8           0.7317          -0.0004           11.84m\n",
      "         9           0.7296           0.0021           12.07m\n",
      "        10           0.7276           0.0088           12.01m\n",
      "        20           0.7230          -0.0005           12.12m\n",
      "        30           0.7226          -0.0032           12.19m\n",
      "[CV] END ccp_alpha=0.00046450412719997725, learning_rate=0.1315089703802877, max_depth=7, max_features=sqrt, min_samples_leaf=43, min_samples_split=27, min_weight_fraction_leaf=0.09488855372533334, n_estimators=515, n_iter_no_change=18, subsample=0.9425192044349383, tol=0.0003146137691733707, validation_fraction=0.10976721140063839; total time=  50.6s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7629          -0.0000            7.19m\n",
      "         2           0.7617          -0.0044            7.03m\n",
      "         3           0.7622           0.0016            7.27m\n",
      "         4           0.7631           0.0036            7.16m\n",
      "         5           0.7629          -0.0009            7.23m\n",
      "         6           0.7623          -0.0022            7.30m\n",
      "         7           0.7618          -0.0018            7.29m\n",
      "         8           0.7630           0.0045            7.22m\n",
      "         9           0.7626          -0.0015            7.15m\n",
      "        10           0.7628           0.0007            7.14m\n",
      "[CV] END ccp_alpha=0.009263008785133489, learning_rate=0.1402154051003889, max_depth=6, max_features=sqrt, min_samples_leaf=12, min_samples_split=21, min_weight_fraction_leaf=0.03308980248526492, n_estimators=247, n_iter_no_change=11, subsample=0.7932946965146986, tol=0.0003351833220267471, validation_fraction=0.1729606178338064; total time=  23.1s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7574           0.0055           47.68m\n",
      "         2           0.7567          -0.0021           48.33m\n",
      "         3           0.7530           0.0093           48.02m\n",
      "         4           0.7466          -0.0013           48.30m\n",
      "         5           0.7479           0.0040           48.30m\n",
      "         6           0.7480           0.0002           48.37m\n",
      "         7           0.7471          -0.0025           48.10m\n",
      "         8           0.7470          -0.0004           47.80m\n",
      "         9           0.7466          -0.0010           47.56m\n",
      "        10           0.7480           0.0039           47.54m\n",
      "[CV] END ccp_alpha=0.0024929222914887497, learning_rate=0.09207658460712595, max_depth=5, max_features=0.7, min_samples_leaf=40, min_samples_split=22, min_weight_fraction_leaf=0.0076979909828793, n_estimators=898, n_iter_no_change=7, subsample=0.7483663861762013, tol=0.0009396976523425732, validation_fraction=0.1808120379564417; total time=  36.7s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7624          -0.0000           23.00m\n",
      "         2           0.7621          -0.0113           21.63m\n",
      "         3           0.7627           0.0257           20.94m\n",
      "         4           0.7627          -0.0021           21.10m\n",
      "         5           0.7624          -0.0139           20.37m\n",
      "         6           0.7626           0.0110           20.42m\n",
      "         7           0.7627           0.0026           20.03m\n",
      "[CV] END ccp_alpha=0.00940523264489604, learning_rate=0.08951440421750446, max_depth=9, max_features=log2, min_samples_leaf=44, min_samples_split=10, min_weight_fraction_leaf=0.06756901170392808, n_estimators=672, n_iter_no_change=6, subsample=0.9774080854835687, tol=0.0008873393533809811, validation_fraction=0.12579416277151556; total time=  13.9s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7531           0.0095           31.54m\n",
      "         2           0.7530          -0.0070           31.24m\n",
      "         3           0.7530          -0.0008           31.52m\n",
      "         4           0.7531           0.0076           30.97m\n",
      "         5           0.7531          -0.0001           30.33m\n",
      "         6           0.7530          -0.0074           30.03m\n",
      "         7           0.7529          -0.0038           29.87m\n",
      "         8           0.7531           0.0086           29.70m\n",
      "         9           0.7531           0.0006           29.43m\n",
      "        10           0.7528          -0.0167           29.62m\n",
      "[CV] END ccp_alpha=0.003492095746126609, learning_rate=0.1551911357740479, max_depth=5, max_features=0.5, min_samples_leaf=28, min_samples_split=63, min_weight_fraction_leaf=0.0779875545857624, n_estimators=827, n_iter_no_change=15, subsample=0.9806904982662842, tol=0.0007953406511139436, validation_fraction=0.16689882547142287; total time=  36.6s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7629          -0.0000           44.96m\n",
      "         2           0.7622          -0.0027           44.84m\n",
      "         3           0.7616          -0.0026           44.73m\n",
      "         4           0.7612          -0.0014           44.65m\n",
      "         5           0.7631           0.0073           44.57m\n",
      "         6           0.7636           0.0022           44.36m\n",
      "         7           0.7633          -0.0011           44.03m\n",
      "[CV] END ccp_alpha=0.0069602979667497305, learning_rate=0.124012234017873, max_depth=4, max_features=None, min_samples_leaf=27, min_samples_split=75, min_weight_fraction_leaf=0.025416364906973878, n_estimators=689, n_iter_no_change=6, subsample=0.7967652292715801, tol=0.0008586697949246744, validation_fraction=0.11366213314420288; total time=  28.7s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7586           0.0039           51.55m\n",
      "         2           0.7552           0.0042           48.80m\n",
      "         3           0.7526           0.0056           48.88m\n",
      "         4           0.7497           0.0034           48.58m\n",
      "         5           0.7473           0.0027           49.24m\n",
      "         6           0.7442          -0.0008           49.35m\n",
      "         7           0.7412          -0.0030           49.66m\n",
      "         8           0.7410           0.0112           49.24m\n",
      "         9           0.7395           0.0024           49.41m\n",
      "        10           0.7362          -0.0065           48.79m\n",
      "        20           0.7369          -0.0008           48.97m\n",
      "[CV] END ccp_alpha=0.0015643704267108605, learning_rate=0.06004857963291907, max_depth=8, max_features=None, min_samples_leaf=29, min_samples_split=10, min_weight_fraction_leaf=0.09548652806631941, n_estimators=903, n_iter_no_change=19, subsample=0.8307018696033672, tol=0.0007400393165618186, validation_fraction=0.10477161276916488; total time= 1.6min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7584           0.0049           28.00m\n",
      "         2           0.7533           0.0022           27.57m\n",
      "         3           0.7519          -0.0037           27.55m\n",
      "         4           0.7531           0.0033           27.60m\n",
      "         5           0.7529          -0.0005           27.33m\n",
      "         6           0.7530           0.0001           27.43m\n",
      "         7           0.7541           0.0030           27.73m\n",
      "         8           0.7521          -0.0053           27.70m\n",
      "         9           0.7535           0.0036           27.73m\n",
      "        10           0.7528          -0.0019           27.73m\n",
      "[CV] END ccp_alpha=0.002932107716980645, learning_rate=0.0757329090739832, max_depth=5, max_features=0.7, min_samples_leaf=40, min_samples_split=62, min_weight_fraction_leaf=0.07915790437258485, n_estimators=768, n_iter_no_change=11, subsample=0.727361830914607, tol=0.0005044203047025815, validation_fraction=0.10575587600166443; total time=  30.3s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7498           0.0120           34.84m\n",
      "         2           0.7504           0.0024           34.96m\n",
      "         3           0.7495          -0.0033           35.60m\n",
      "         4           0.7497           0.0006           35.08m\n",
      "         5           0.7498           0.0006           35.03m\n",
      "         6           0.7508           0.0037           35.20m\n",
      "         7           0.7496          -0.0047           35.37m\n",
      "         8           0.7507           0.0043           35.33m\n",
      "         9           0.7503          -0.0013           35.50m\n",
      "        10           0.7504           0.0003           35.54m\n",
      "[CV] END ccp_alpha=0.003745401188473625, learning_rate=0.20014286128198325, max_depth=5, max_features=0.7, min_samples_leaf=25, min_samples_split=92, min_weight_fraction_leaf=0.00999749158180029, n_estimators=658, n_iter_no_change=12, subsample=0.8001125833417065, tol=0.00015286681792194077, validation_fraction=0.1650888472948853; total time=  44.5s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7555           0.0069           21.68m\n",
      "         2           0.7499           0.0116           21.65m\n",
      "         3           0.7432          -0.0019           22.23m\n",
      "         4           0.7394           0.0126           22.58m\n",
      "         5           0.7344          -0.0046           22.46m\n",
      "         6           0.7312           0.0124           22.37m\n",
      "         7           0.7276          -0.0007           22.02m\n",
      "         8           0.7254           0.0023           22.20m\n",
      "         9           0.7231          -0.0007           22.11m\n",
      "        10           0.7219           0.0013           22.00m\n",
      "        20           0.7138           0.0015           21.70m\n",
      "[CV] END ccp_alpha=0.00015636406741193932, learning_rate=0.09468029614127392, max_depth=3, max_features=0.5, min_samples_leaf=12, min_samples_split=97, min_weight_fraction_leaf=0.0014079822715084456, n_estimators=698, n_iter_no_change=5, subsample=0.9134025858245949, tol=0.0008001755405312057, validation_fraction=0.16059599747810116; total time=  48.9s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7502           0.0122            8.07m\n",
      "         2           0.7501          -0.0004            8.10m\n",
      "         3           0.7515           0.0050            8.05m\n",
      "         4           0.7503          -0.0044            7.87m\n",
      "         5           0.7497          -0.0020            7.86m\n",
      "         6           0.7491          -0.0025            7.81m\n",
      "         7           0.7503           0.0044            7.76m\n",
      "         8           0.7497          -0.0019            7.64m\n",
      "         9           0.7499           0.0004            7.65m\n",
      "        10           0.7498          -0.0001            7.65m\n",
      "[CV] END ccp_alpha=0.0033761517140362797, learning_rate=0.19858194078250385, max_depth=8, max_features=sqrt, min_samples_leaf=16, min_samples_split=48, min_weight_fraction_leaf=0.04972485058923855, n_estimators=312, n_iter_no_change=9, subsample=0.7854521483132403, tol=4.68869473545328e-05, validation_fraction=0.1609564333979897; total time=  16.4s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7623          -0.0000           20.47m\n",
      "         2           0.7593           0.0050           21.07m\n",
      "         3           0.7595           0.0031           20.94m\n",
      "         4           0.7597           0.0030           21.23m\n",
      "         5           0.7591          -0.0090           21.12m\n",
      "         6           0.7596           0.0072           21.27m\n",
      "         7           0.7590          -0.0092           21.35m\n",
      "         8           0.7568           0.0095           21.47m\n",
      "         9           0.7564          -0.0064           21.47m\n",
      "        10           0.7573           0.0142           21.78m\n",
      "[CV] END ccp_alpha=0.0032078006497173583, learning_rate=0.04730370207997085, max_depth=7, max_features=0.3, min_samples_leaf=24, min_samples_split=68, min_weight_fraction_leaf=0.022024104756554832, n_estimators=545, n_iter_no_change=7, subsample=0.9428503138419145, tol=0.0003586659872917294, validation_fraction=0.10961765510914208; total time=  38.3s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7638          -0.0000           11.75m\n",
      "         2           0.7613          -0.0075           10.62m\n",
      "         3           0.7628           0.0046           10.22m\n",
      "         4           0.7641           0.0040           10.05m\n",
      "         5           0.7635          -0.0018           10.03m\n",
      "         6           0.7620          -0.0046            9.90m\n",
      "         7           0.7617          -0.0009            9.86m\n",
      "         8           0.7611          -0.0017            9.84m\n",
      "[CV] END ccp_alpha=0.009283185625877254, learning_rate=0.09563682966346286, max_depth=7, max_features=0.3, min_samples_leaf=37, min_samples_split=72, min_weight_fraction_leaf=0.030569701928718187, n_estimators=360, n_iter_no_change=7, subsample=0.7508478240058277, tol=0.0005668012624583502, validation_fraction=0.1936154774160781; total time=  14.8s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7622          -0.0000           13.49m\n",
      "         2           0.7626           0.0021           14.23m\n",
      "         3           0.7626           0.0001           14.67m\n",
      "         4           0.7626          -0.0001           15.26m\n",
      "         5           0.7628           0.0010           15.34m\n",
      "         6           0.7626          -0.0010           15.46m\n",
      "         7           0.7630           0.0022           15.34m\n",
      "         8           0.7631           0.0007           15.28m\n",
      "         9           0.7623          -0.0047           15.06m\n",
      "        10           0.7626           0.0019           15.13m\n",
      "[CV] END ccp_alpha=0.007089109969101186, learning_rate=0.12056399538158155, max_depth=4, max_features=log2, min_samples_leaf=39, min_samples_split=59, min_weight_fraction_leaf=0.08670723185801038, n_estimators=724, n_iter_no_change=16, subsample=0.8534027196582813, tol=0.0005115162946871996, validation_fraction=0.17982951789667753; total time=  22.4s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7621          -0.0000           20.25m\n",
      "         2           0.7623           0.0022           20.98m\n",
      "         3           0.7627           0.0042           21.55m\n",
      "         4           0.7630           0.0025           21.65m\n",
      "         5           0.7624          -0.0059           22.00m\n",
      "         6           0.7632           0.0081           22.48m\n",
      "         7           0.7625          -0.0071           22.94m\n",
      "         8           0.7626           0.0008           22.89m\n",
      "         9           0.7631           0.0048           22.60m\n",
      "        10           0.7625          -0.0058           22.67m\n",
      "        20           0.7632           0.0018           22.14m\n",
      "[CV] END ccp_alpha=0.003988209014447946, learning_rate=0.0967041475161484, max_depth=4, max_features=log2, min_samples_leaf=41, min_samples_split=99, min_weight_fraction_leaf=0.09626484146779252, n_estimators=990, n_iter_no_change=19, subsample=0.9087922618281093, tol=0.00041895294441426993, validation_fraction=0.11732943200708458; total time=  28.6s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7475           0.0153           68.70m\n",
      "         2           0.7414           0.0141           67.24m\n",
      "         3           0.7326           0.0051           68.14m\n",
      "         4           0.7268          -0.0001           68.15m\n",
      "         5           0.7239           0.0154           67.92m\n",
      "         6           0.7203          -0.0134           67.52m\n",
      "         7           0.7183           0.0035           66.87m\n",
      "         8           0.7172          -0.0028           66.68m\n",
      "         9           0.7162           0.0093           66.46m\n",
      "        10           0.7164           0.0052           66.00m\n",
      "        20           0.7125          -0.0224           65.33m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7623          -0.0000           14.78m\n",
      "         2           0.7634           0.0035           13.90m\n",
      "         3           0.7627          -0.0022           13.79m\n",
      "         4           0.7606          -0.0063           13.67m\n",
      "         5           0.7611           0.0014           13.52m\n",
      "         6           0.7632           0.0065           13.47m\n",
      "         7           0.7615          -0.0051           13.41m\n",
      "         8           0.7646           0.0094           13.27m\n",
      "         9           0.7628          -0.0056           13.21m\n",
      "[CV] END ccp_alpha=0.006842330265121569, learning_rate=0.09803049874792026, max_depth=9, max_features=0.5, min_samples_leaf=12, min_samples_split=56, min_weight_fraction_leaf=0.017336465350777208, n_estimators=280, n_iter_no_change=8, subsample=0.7546708263364187, tol=0.0007653614103176525, validation_fraction=0.1425155874491245; total time=  27.8s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7588           0.0045            8.54m\n",
      "         2           0.7539           0.0031            9.09m\n",
      "         3           0.7520           0.0031            8.71m\n",
      "         4           0.7478           0.0003            8.42m\n",
      "         5           0.7472          -0.0020            8.10m\n",
      "         6           0.7490           0.0065            7.84m\n",
      "         7           0.7437          -0.0016            7.90m\n",
      "         8           0.7432           0.0044            7.82m\n",
      "         9           0.7404           0.0019            7.84m\n",
      "        10           0.7387           0.0040            7.87m\n",
      "        20           0.7257           0.0077            7.79m\n",
      "        30           0.7219           0.0001            7.55m\n",
      "        40           0.7220          -0.0016            7.47m\n",
      "[CV] END ccp_alpha=0.00045227288910538066, learning_rate=0.07506606615265286, max_depth=7, max_features=log2, min_samples_leaf=28, min_samples_split=35, min_weight_fraction_leaf=0.0965255307264138, n_estimators=387, n_iter_no_change=16, subsample=0.782799754606763, tol=0.0003062735057040824, validation_fraction=0.11652669390630026; total time= 1.0min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7501           0.0124            8.00m\n",
      "         2           0.7500          -0.0003            8.33m\n",
      "         3           0.7514           0.0049            8.33m\n",
      "         4           0.7502          -0.0045            8.07m\n",
      "         5           0.7497          -0.0018            7.95m\n",
      "         6           0.7490          -0.0025            7.98m\n",
      "         7           0.7502           0.0043            7.93m\n",
      "         8           0.7497          -0.0019            7.77m\n",
      "         9           0.7497           0.0003            7.73m\n",
      "        10           0.7498           0.0001            7.70m\n",
      "[CV] END ccp_alpha=0.0033761517140362797, learning_rate=0.19858194078250385, max_depth=8, max_features=sqrt, min_samples_leaf=16, min_samples_split=48, min_weight_fraction_leaf=0.04972485058923855, n_estimators=312, n_iter_no_change=9, subsample=0.7854521483132403, tol=4.68869473545328e-05, validation_fraction=0.1609564333979897; total time=  16.9s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7550           0.0071           20.05m\n",
      "         2           0.7501           0.0111           19.18m\n",
      "         3           0.7462           0.0013           18.87m\n",
      "         4           0.7417           0.0071           19.00m\n",
      "         5           0.7375           0.0018           18.93m\n",
      "         6           0.7349           0.0017           18.91m\n",
      "         7           0.7337           0.0061           18.84m\n",
      "         8           0.7310          -0.0025           18.92m\n",
      "         9           0.7304           0.0052           18.89m\n",
      "        10           0.7292           0.0053           18.89m\n",
      "        20           0.7251          -0.0082           18.45m\n",
      "[CV] END ccp_alpha=0.0008085332633271525, learning_rate=0.0839308912122809, max_depth=3, max_features=None, min_samples_leaf=28, min_samples_split=78, min_weight_fraction_leaf=0.06323058305935796, n_estimators=397, n_iter_no_change=10, subsample=0.8607324052224274, tol=0.0001002897700544083, validation_fraction=0.1835302495589238; total time= 1.1min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7621          -0.0000           50.54m\n",
      "         2           0.7627           0.0059           49.72m\n",
      "         3           0.7623          -0.0038           47.63m\n",
      "         4           0.7627           0.0031           46.99m\n",
      "         5           0.7623          -0.0037           47.35m\n",
      "         6           0.7624           0.0011           47.32m\n",
      "         7           0.7629           0.0047           47.07m\n",
      "         8           0.7626          -0.0023           46.75m\n",
      "         9           0.7625          -0.0010           46.37m\n",
      "        10           0.7623          -0.0018           46.59m\n",
      "[CV] END ccp_alpha=0.006499639307777652, learning_rate=0.1503933754515407, max_depth=8, max_features=0.5, min_samples_leaf=27, min_samples_split=24, min_weight_fraction_leaf=0.0375582952639944, n_estimators=999, n_iter_no_change=11, subsample=0.9016078405885598, tol=0.00033815266747473194, validation_fraction=0.11550416167277443; total time=  35.5s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7478           0.0150           68.03m\n",
      "         2           0.7385           0.0191           68.41m\n",
      "         3           0.7322          -0.0016           68.50m\n",
      "         4           0.7270           0.0139           67.69m\n",
      "         5           0.7226          -0.0099           67.35m\n",
      "         6           0.7198           0.0102           67.20m\n",
      "         7           0.7178          -0.0072           67.08m\n",
      "         8           0.7162           0.0089           66.59m\n",
      "         9           0.7150          -0.0047           66.36m\n",
      "        10           0.7152           0.0032           66.53m\n",
      "        20           0.7133          -0.0033           66.20m\n",
      "[CV] END ccp_alpha=0.00017161101831750236, learning_rate=0.16267288460078222, max_depth=7, max_features=0.5, min_samples_leaf=37, min_samples_split=32, min_weight_fraction_leaf=0.004805892419703373, n_estimators=957, n_iter_no_change=9, subsample=0.9660041161894142, tol=0.000270893623341714, validation_fraction=0.10153045402903849; total time= 1.7min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7623          -0.0000           25.06m\n",
      "         2           0.7625           0.0032           24.66m\n",
      "         3           0.7625          -0.0009           24.26m\n",
      "         4           0.7624          -0.0014           24.31m\n",
      "         5           0.7624           0.0002           24.49m\n",
      "         6           0.7623          -0.0011           24.41m\n",
      "         7           0.7631           0.0110           24.72m\n",
      "         8           0.7627          -0.0055           24.61m\n",
      "[CV] END ccp_alpha=0.008127995672575026, learning_rate=0.19944971547677176, max_depth=3, max_features=0.7, min_samples_leaf=8, min_samples_split=45, min_weight_fraction_leaf=0.03762595855309158, n_estimators=614, n_iter_no_change=7, subsample=0.9331440747782309, tol=0.0005684042497358051, validation_fraction=0.14242220092469765; total time=  20.8s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7627          -0.0000            9.49m\n",
      "         2           0.7625          -0.0034            9.36m\n",
      "         3           0.7572           0.0065            9.09m\n",
      "         4           0.7535           0.0143            9.08m\n",
      "         5           0.7491           0.0003            9.08m\n",
      "         6           0.7448          -0.0022            8.97m\n",
      "         7           0.7447          -0.0024            8.84m\n",
      "         8           0.7445          -0.0019            8.94m\n",
      "         9           0.7447           0.0017            8.87m\n",
      "        10           0.7448           0.0023            8.70m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7623          -0.0000           13.99m\n",
      "         2           0.7634           0.0035           13.30m\n",
      "         3           0.7627          -0.0022           13.24m\n",
      "         4           0.7606          -0.0063           13.34m\n",
      "         5           0.7611           0.0014           13.30m\n",
      "         6           0.7632           0.0065           13.23m\n",
      "         7           0.7615          -0.0051           13.13m\n",
      "         8           0.7646           0.0094           12.97m\n",
      "         9           0.7628          -0.0056           12.85m\n",
      "[CV] END ccp_alpha=0.006842330265121569, learning_rate=0.09803049874792026, max_depth=9, max_features=0.5, min_samples_leaf=12, min_samples_split=56, min_weight_fraction_leaf=0.017336465350777208, n_estimators=280, n_iter_no_change=8, subsample=0.7546708263364187, tol=0.0007653614103176525, validation_fraction=0.1425155874491245; total time=  27.4s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7624          -0.0000           12.14m\n",
      "         2           0.7624          -0.0011           13.68m\n",
      "         3           0.7546           0.0059           13.05m\n",
      "         4           0.7480           0.0017           12.49m\n",
      "         5           0.7483           0.0117           12.07m\n",
      "         6           0.7437           0.0079           11.80m\n",
      "         7           0.7394           0.0080           11.78m\n",
      "         8           0.7392          -0.0071           11.78m\n",
      "         9           0.7393           0.0022           11.66m\n",
      "        10           0.7393           0.0018           11.77m\n",
      "        20           0.7394           0.0055           11.31m\n",
      "[CV] END ccp_alpha=0.0020794166286818884, learning_rate=0.1235400655639983, max_depth=7, max_features=log2, min_samples_leaf=30, min_samples_split=53, min_weight_fraction_leaf=0.09394989415641891, n_estimators=469, n_iter_no_change=19, subsample=0.976562270506935, tol=9.849250205191949e-05, validation_fraction=0.11959828624191453; total time=  41.4s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7613          -0.0000           32.60m\n",
      "         2           0.7626           0.0051           32.75m\n",
      "         3           0.7617          -0.0034           32.93m\n",
      "         4           0.7627           0.0040           33.21m\n",
      "         5           0.7630           0.0009           32.89m\n",
      "         6           0.7626          -0.0015           32.88m\n",
      "[CV] END ccp_alpha=0.0052273282938199404, learning_rate=0.09550820367170992, max_depth=4, max_features=0.5, min_samples_leaf=17, min_samples_split=60, min_weight_fraction_leaf=0.0031429185686734254, n_estimators=942, n_iter_no_change=5, subsample=0.794306794322898, tol=0.0005185706911647028, validation_fraction=0.1907566473926093; total time=  14.3s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7622          -0.0000           12.34m\n",
      "         2           0.7635           0.0038           14.74m\n",
      "         3           0.7626          -0.0025           16.35m\n",
      "         4           0.7623          -0.0010           15.80m\n",
      "         5           0.7628           0.0012           15.48m\n",
      "         6           0.7624          -0.0009           15.05m\n",
      "         7           0.7627           0.0009           14.79m\n",
      "         8           0.7639           0.0032           14.65m\n",
      "         9           0.7612          -0.0075           14.60m\n",
      "        10           0.7631           0.0055           14.41m\n",
      "[CV] END ccp_alpha=0.006334037565104235, learning_rate=0.18429211803754356, max_depth=6, max_features=0.5, min_samples_leaf=48, min_samples_split=93, min_weight_fraction_leaf=0.08925589984899779, n_estimators=530, n_iter_no_change=14, subsample=0.736626386410202, tol=0.0003662978380769749, validation_fraction=0.19068284415457543; total time=  26.1s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7597           0.0031           22.79m\n",
      "         2           0.7601           0.0067           22.50m\n",
      "         3           0.7593          -0.0138           22.29m\n",
      "         4           0.7595           0.0033           22.43m\n",
      "         5           0.7567           0.0028           22.34m\n",
      "         6           0.7572           0.0078           22.56m\n",
      "         7           0.7540          -0.0049           22.13m\n",
      "         8           0.7537          -0.0055           22.19m\n",
      "         9           0.7538           0.0019           22.40m\n",
      "        10           0.7537          -0.0010           22.50m\n",
      "[CV] END ccp_alpha=0.0032078006497173583, learning_rate=0.04730370207997085, max_depth=7, max_features=0.3, min_samples_leaf=24, min_samples_split=68, min_weight_fraction_leaf=0.022024104756554832, n_estimators=545, n_iter_no_change=7, subsample=0.9428503138419145, tol=0.0003586659872917294, validation_fraction=0.10961765510914208; total time=  36.7s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7558           0.0070           18.35m\n",
      "         2           0.7501           0.0023           21.27m\n",
      "         3           0.7457           0.0063           21.01m\n",
      "         4           0.7458           0.0010           20.00m\n",
      "         5           0.7457          -0.0038           19.46m\n",
      "         6           0.7455          -0.0058           19.09m\n",
      "         7           0.7456           0.0055           19.09m\n",
      "         8           0.7456          -0.0023           18.66m\n",
      "         9           0.7457           0.0031           18.37m\n",
      "        10           0.7456          -0.0043           18.27m\n",
      "        20           0.7455           0.0042           17.32m\n",
      "[CV] END ccp_alpha=0.002301852682415553, learning_rate=0.10983867597695046, max_depth=6, max_features=0.3, min_samples_leaf=21, min_samples_split=53, min_weight_fraction_leaf=0.09404585843529144, n_estimators=676, n_iter_no_change=18, subsample=0.9744593170661344, tol=0.0003801587002554444, validation_fraction=0.10154566165288675; total time=  35.1s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7626          -0.0000           32.80m\n",
      "         2           0.7625          -0.0097           34.50m\n",
      "         3           0.7625          -0.0031           34.15m\n",
      "         4           0.7623          -0.0253           34.18m\n",
      "         5           0.7627           0.0445           34.26m\n",
      "         6           0.7625          -0.0199           34.66m\n",
      "         7           0.7625           0.0019           35.04m\n",
      "         8           0.7627           0.0160           35.18m\n",
      "         9           0.7623          -0.0343           35.36m\n",
      "        10           0.7626           0.0230           35.05m\n",
      "[CV] END ccp_alpha=0.0062289047581900025, learning_rate=0.0270694929987536, max_depth=7, max_features=0.5, min_samples_leaf=34, min_samples_split=56, min_weight_fraction_leaf=0.06995122107671939, n_estimators=855, n_iter_no_change=17, subsample=0.9908610601342476, tol=0.0007245951041799522, validation_fraction=0.10410675167678758; total time=  46.3s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7613           0.0016           21.70m\n",
      "         2           0.7588          -0.0031           21.24m\n",
      "         3           0.7580           0.0046           21.12m\n",
      "         4           0.7572           0.0036           21.04m\n",
      "         5           0.7554          -0.0004           20.94m\n",
      "         6           0.7545           0.0026           20.87m\n",
      "         7           0.7523          -0.0027           20.73m\n",
      "         8           0.7524           0.0067           20.71m\n",
      "         9           0.7505          -0.0021           20.91m\n",
      "        10           0.7490          -0.0011           20.95m\n",
      "        20           0.7428           0.0028           20.24m\n",
      "        30           0.7413          -0.0044           19.38m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7533           0.0094           19.90m\n",
      "         2           0.7482           0.0033           19.51m\n",
      "         3           0.7433           0.0085           19.51m\n",
      "         4           0.7380           0.0024           19.08m\n",
      "         5           0.7349           0.0096           19.40m\n",
      "         6           0.7312          -0.0006           19.30m\n",
      "         7           0.7282           0.0031           19.07m\n",
      "         8           0.7265           0.0010           19.06m\n",
      "         9           0.7254           0.0099           19.11m\n",
      "        10           0.7233          -0.0068           19.28m\n",
      "        20           0.7147          -0.0075           18.64m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=GradientBoostingClassifier(random_state=42,\n",
       "                                                        verbose=1),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;ccp_alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fa4abe9b370&gt;,\n",
       "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fa4abe98b80&gt;,\n",
       "                                        &#x27;max_depth&#x27;: &lt;scipy.stats._distn_inf...\n",
       "                                        &#x27;n_iter_no_change&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7fa4abe9b940&gt;,\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fa4abe9a320&gt;,\n",
       "                                        &#x27;tol&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fa4abe9b6d0&gt;,\n",
       "                                        &#x27;validation_fraction&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fa4abe981f0&gt;},\n",
       "                   random_state=42, return_train_score=True, scoring=&#x27;roc_auc&#x27;,\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomizedSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">GradientBoost...42, verbose=1)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_distributions',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">param_distributions&nbsp;</td>\n",
       "            <td class=\"value\">{&#x27;ccp_alpha&#x27;: &lt;scipy.stats....x7fa4abe9b370&gt;, &#x27;learning_rate&#x27;: &lt;scipy.stats....x7fa4abe98b80&gt;, &#x27;max_depth&#x27;: &lt;scipy.stats....x7fa4abe9a7a0&gt;, &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, ...], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_iter&nbsp;</td>\n",
       "            <td class=\"value\">50</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scoring&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;roc_auc&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">refit&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">pre_dispatch&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">error_score&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_train_score&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: GradientBoostingClassifier</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>GradientBoostingClassifier(ccp_alpha=np.float64(0.00015636406741193932),\n",
       "                           learning_rate=np.float64(0.09468029614127392),\n",
       "                           max_features=0.5, min_samples_leaf=12,\n",
       "                           min_samples_split=97,\n",
       "                           min_weight_fraction_leaf=np.float64(0.0014079822715084456),\n",
       "                           n_estimators=698, n_iter_no_change=5,\n",
       "                           random_state=42,\n",
       "                           subsample=np.float64(0.9134025858245949),\n",
       "                           tol=np.float64(0.0008001755405312057),\n",
       "                           validation_fraction=np.float64(0.16059599747810116),\n",
       "                           verbose=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('loss',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">loss&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;log_loss&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(0....8029614127392)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">698</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(0.9134025858245949)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;friedman_mse&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">97</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">12</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(0....9822715084456)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('init',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">init&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">0.5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_fraction',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validation_fraction&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(0....9599747810116)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter_no_change',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_iter_no_change&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(0....1755405312057)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(0....6406741193932)</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=GradientBoostingClassifier(random_state=42,\n",
       "                                                        verbose=1),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'ccp_alpha': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fa4abe9b370>,\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fa4abe98b80>,\n",
       "                                        'max_depth': <scipy.stats._distn_inf...\n",
       "                                        'n_iter_no_change': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7fa4abe9b940>,\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fa4abe9a320>,\n",
       "                                        'tol': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fa4abe9b6d0>,\n",
       "                                        'validation_fraction': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fa4abe981f0>},\n",
       "                   random_state=42, return_train_score=True, scoring='roc_auc',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_random_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gb_model = gb_random_search.best_estimator_\n",
    "\n",
    "gb_pred_proba = best_gb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "gb_pred_binary = best_gb_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Performance:\n",
      "ROC-AUC Score: 0.6900\n",
      "Accuracy Score: 0.8722\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93    394330\n",
      "           1       0.00      0.00      0.00     57804\n",
      "\n",
      "    accuracy                           0.87    452134\n",
      "   macro avg       0.44      0.50      0.47    452134\n",
      "weighted avg       0.76      0.87      0.81    452134\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "\n",
    "gb_roc_auc = roc_auc_score(y_test, gb_pred_proba)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred_binary)\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"ROC-AUC Score: {gb_roc_auc:.4f}\")\n",
    "print(f\"Accuracy Score: {gb_accuracy:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, gb_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grade</td>\n",
       "      <td>0.672443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>int_rate</td>\n",
       "      <td>0.295058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>home_ownership</td>\n",
       "      <td>0.011743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>revol_util</td>\n",
       "      <td>0.007154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loan_amnt</td>\n",
       "      <td>0.005413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>0.004411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dti</td>\n",
       "      <td>0.003777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>delinq_2yrs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>emp_length</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>purpose</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  importance\n",
       "2           grade    0.672443\n",
       "1        int_rate    0.295058\n",
       "8  home_ownership    0.011743\n",
       "6      revol_util    0.007154\n",
       "0       loan_amnt    0.005413\n",
       "3      annual_inc    0.004411\n",
       "4             dti    0.003777\n",
       "5     delinq_2yrs    0.000000\n",
       "7      emp_length    0.000000\n",
       "9         purpose    0.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': best_gb_model.feature_importances_  \n",
    "}).sort_values('importance', ascending=False)  \n",
    "\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "plt.title('Feature Importance from Gradient Boosting Model')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
